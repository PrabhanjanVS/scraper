# =================================
# DATABASE CONFIGURATION (Docker)
# =================================
# PostgreSQL database URL for Docker container
DATABASE_URL=postgresql://postgres:mypassword123@localhost:5432/amazon_scraper

# =================================
# REDIS CONFIGURATION (Docker)
# =================================
# Redis URL for Docker container
REDIS_URL=redis://localhost:6379

# Redis queue names
SCRAPING_QUEUE_NAME=scraping_jobs
RESULTS_QUEUE_NAME=scraping_results

# =================================
# SCRAPING CONFIGURATION
# =================================
# Whether to use proxies (true/false)
USE_PROXIES=false

# Proxy rotation settings
PROXY_ROTATION_LIMIT=5
PROXY_TEST_TIMEOUT=10

# Rate limiting settings
REQUEST_DELAY_MIN=2
REQUEST_DELAY_MAX=5
MAX_CONCURRENT_REQUESTS=2

# Scraping limits
MAX_PAGES_PER_CATEGORY=3
MAX_PRODUCTS_PER_PAGE=50
SCRAPING_TIMEOUT=60

# =================================
# USER AGENT ROTATION
# =================================
USER_AGENTS=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36,Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36,Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/116.0

# =================================
# MONITORING CONFIGURATION
# =================================
# Prometheus metrics port
PROMETHEUS_PORT=8000

# Grafana port
GRAFANA_PORT=3000

# Alert thresholds
MAX_FAILURE_RATE=0.1
MIN_SUCCESS_RATE=0.9

# Health check intervals (minutes)
HEALTH_CHECK_INTERVAL=60
SCRAPING_SCHEDULE=0 */6 * * *

# =================================
# EMAIL ALERT CONFIGURATION
# =================================
# SMTP server settings for email alerts
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password
ALERT_EMAIL=admin@yourcompany.com

# Email alert settings
ENABLE_EMAIL_ALERTS=true
ALERT_ON_SCRAPING_FAILURE=true
ALERT_ON_NO_ACTIVITY=true
ALERT_COOLDOWN_MINUTES=30

# =================================
# LOGGING CONFIGURATION
# =================================
LOG_LEVEL=INFO
LOG_FILE=amazon_scraper.log
LOG_MAX_SIZE=10MB
LOG_BACKUP_COUNT=5
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# =================================
# DOCKER ENVIRONMENT
# =================================
DOCKER_ENV=true
CONTAINER_NAME=amazon-scraper
NETWORK_NAME=scraper-network

# =================================
# SCHEDULER CONFIGURATION
# =================================
# Cron schedule for automatic scraping
# Format: minute hour day month day_of_week
# Examples:
# "0 */6 * * *" = every 6 hours
# "0 9,21 * * *" = at 9 AM and 9 PM daily
# "0 9 * * 1-5" = at 9 AM on weekdays
SCRAPING_SCHEDULE=0 */6 * * *

# Scheduler timezone
SCHEDULER_TIMEZONE=Asia/Kolkata

# Enable/disable scheduled scraping
ENABLE_SCHEDULER=true

# =================================
# CATEGORIES TO SCRAPE
# =================================
# Comma-separated list of categories to scrape
SCRAPE_CATEGORIES=laptops,smartphones,headphones,tablets,cameras

# Category URLs (can be customized)
CATEGORY_LAPTOP_URL=https://www.amazon.in/s?k=laptop
CATEGORY_SMARTPHONE_URL=https://www.amazon.in/s?k=smartphone
CATEGORY_HEADPHONES_URL=https://www.amazon.in/s?k=headphones
CATEGORY_TABLETS_URL=https://www.amazon.in/s?k=tablet
CATEGORY_CAMERAS_URL=https://www.amazon.in/s?k=camera

# =================================
# CAPTCHA SOLVING (Optional)
# =================================
# 2Captcha API key (if using captcha solving service)
CAPTCHA_API_KEY=your_2captcha_api_key_here

# Captcha solving timeout (seconds)
CAPTCHA_TIMEOUT=120

# Enable/disable captcha solving
ENABLE_CAPTCHA_SOLVING=false

# =================================
# PROXY PROVIDERS (Optional)
# =================================
# If using proxy services, add their configurations here
# BRIGHTDATA_USERNAME=your_username
# BRIGHTDATA_PASSWORD=your_password
# BRIGHTDATA_ENDPOINT=zproxy.lum-superproxy.io:22225

# OXYLABS_USERNAME=your_username
# OXYLABS_PASSWORD=your_password
# OXYLABS_ENDPOINT=pr.oxylabs.io:7777

# Free proxy settings
ENABLE_FREE_PROXIES=false
FREE_PROXY_TEST_TIMEOUT=10

# =================================
# AWS CONFIGURATION (Optional)
# =================================
# If deploying on AWS or using AWS services
# AWS_ACCESS_KEY_ID=your_access_key
# AWS_SECRET_ACCESS_KEY=your_secret_key
# AWS_REGION=us-east-1
# S3_BUCKET_NAME=amazon-scraper-data

# =================================
# API CONFIGURATION (Optional)
# =================================
# If you want to expose an API for the scraper
API_PORT=8080
API_HOST=0.0.0.0
API_SECRET_KEY=your_secret_key_for_api_authentication
ENABLE_API=false

# =================================
# NOTIFICATION SETTINGS
# =================================
# Slack webhook for notifications (optional)
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK
ENABLE_SLACK_NOTIFICATIONS=false

# Discord webhook (optional)
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/YOUR/WEBHOOK
ENABLE_DISCORD_NOTIFICATIONS=false

# =================================
# DATA BACKUP SETTINGS
# =================================
# Enable automatic backups
ENABLE_BACKUPS=true

# Backup frequency (hours)
BACKUP_FREQUENCY_HOURS=24

# Backup retention (days)
BACKUP_RETENTION_DAYS=30

# Backup location
BACKUP_DIRECTORY=./backups

# =================================
# PERFORMANCE SETTINGS
# =================================
# Browser settings
BROWSER_HEADLESS=true
BROWSER_TIMEOUT=60
PAGE_LOAD_TIMEOUT=30

# Request settings
MAX_RETRIES=3
RETRY_DELAY=5
CONNECTION_TIMEOUT=30

# =================================
# DEVELOPMENT SETTINGS
# =================================
# Debug mode
DEBUG_MODE=false

# Test mode (limits scraping for testing)
TEST_MODE=false
TEST_MAX_PAGES=1
TEST_MAX_PRODUCTS=10

# Enable detailed logging
VERBOSE_LOGGING=false

# =================================
# SECURITY SETTINGS
# =================================
# Database connection pool settings
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_TIMEOUT=30

# Redis connection settings
REDIS_SOCKET_TIMEOUT=30
REDIS_CONNECTION_POOL_MAX_CONNECTIONS=10

# Session settings
SESSION_TIMEOUT=3600
MAX_SESSIONS=100
